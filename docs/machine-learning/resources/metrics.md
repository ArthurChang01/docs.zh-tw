---
title: ML.NET 計量
description: 了解用於評估 ML.NET 模型效能的計量
ms.date: 12/17/2019
author: natke
ms.author: nakersha
ms.openlocfilehash: b154c88281b65730c107a52034dfa40a45d4e367
ms.sourcegitcommit: 30a558d23e3ac5a52071121a52c305c85fe15726
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 12/25/2019
ms.locfileid: "75347760"
---
# <a name="evaluate-your-mlnet-model-with-metrics"></a><span data-ttu-id="f3668-103">使用計量評估您的 ML.NET 模型</span><span class="sxs-lookup"><span data-stu-id="f3668-103">Evaluate your ML.NET model with metrics</span></span>

<span data-ttu-id="f3668-104">瞭解用來評估 ML.NET 模型的計量。</span><span class="sxs-lookup"><span data-stu-id="f3668-104">Understand the metrics used to evaluate an ML.NET model.</span></span>

<span data-ttu-id="f3668-105">評估計量是模型所執行的機器學習工作類型特有的。</span><span class="sxs-lookup"><span data-stu-id="f3668-105">Evaluation metrics are specific to the type of machine learning task that a model performs.</span></span>

<span data-ttu-id="f3668-106">例如，針對分類工作，會測量預測分類與實體類別目錄的符合程度來評估模型。</span><span class="sxs-lookup"><span data-stu-id="f3668-106">For example, for the classification task, the model is evaluated by measuring how well a predicted category matches the actual category.</span></span> <span data-ttu-id="f3668-107">而對於叢集而言，評估是以彼此接近的叢集專案，以及叢集之間有多少區隔為基礎。</span><span class="sxs-lookup"><span data-stu-id="f3668-107">And for clustering, evaluation is based on how close clustered items are to each other, and how much separation there is between the clusters.</span></span>

## <a name="evaluation-metrics-for-binary-classification"></a><span data-ttu-id="f3668-108">二元分類的評估度量</span><span class="sxs-lookup"><span data-stu-id="f3668-108">Evaluation metrics for Binary Classification</span></span>

| <span data-ttu-id="f3668-109">計量</span><span class="sxs-lookup"><span data-stu-id="f3668-109">Metrics</span></span>   |      <span data-ttu-id="f3668-110">描述</span><span class="sxs-lookup"><span data-stu-id="f3668-110">Description</span></span>      |  <span data-ttu-id="f3668-111">尋找 [程式和功能] 中所列的</span><span class="sxs-lookup"><span data-stu-id="f3668-111">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="f3668-112">**準確度**</span><span class="sxs-lookup"><span data-stu-id="f3668-112">**Accuracy**</span></span> |  <span data-ttu-id="f3668-113">[準確度](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification)是使用測試資料集進行正確預測的比例。</span><span class="sxs-lookup"><span data-stu-id="f3668-113">[Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) is the proportion of correct predictions with a test data set.</span></span> <span data-ttu-id="f3668-114">它是正確預測數佔總輸入樣本數的比例。</span><span class="sxs-lookup"><span data-stu-id="f3668-114">It is the ratio of number of correct predictions to the total number of input samples.</span></span> <span data-ttu-id="f3668-115">如果有相同數目的樣本屬於每個類別，它會運作良好。</span><span class="sxs-lookup"><span data-stu-id="f3668-115">It works well if there are similar number of samples belonging to each class.</span></span>| <span data-ttu-id="f3668-116">**越接近 1.00 越好**。</span><span class="sxs-lookup"><span data-stu-id="f3668-116">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="f3668-117">但剛好 1.00 表示有問題 (通常是標籤/目標外洩、過度擬合或使用定型資料進行測試)。</span><span class="sxs-lookup"><span data-stu-id="f3668-117">But exactly 1.00 indicates an issue (commonly: label/target leakage, over-fitting, or testing with training data).</span></span> <span data-ttu-id="f3668-118">當測試資料不對稱（其中大部分的實例屬於其中一個類別）、資料集很小，或分數方法0.00 或1.00 時，精確度並不會真正捕捉分類器的有效性，而且您必須檢查其他計量。</span><span class="sxs-lookup"><span data-stu-id="f3668-118">When the test data is unbalanced (where most of the instances belong to one of the classes), the dataset is small, or scores approach 0.00 or 1.00, then accuracy doesn’t really capture the effectiveness of a classifier and you need to check additional metrics.</span></span> |
| <span data-ttu-id="f3668-119">**AUC**</span><span class="sxs-lookup"><span data-stu-id="f3668-119">**AUC**</span></span> |    <span data-ttu-id="f3668-120">*曲線下*的[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)或面積會測量所建立之曲線下的區域，並將實際的正向與錯誤的正面速率進行比對。</span><span class="sxs-lookup"><span data-stu-id="f3668-120">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) or *Area under the curve* measures the area under the curve created by sweeping the true positive rate vs. the false positive rate.</span></span>  |   <span data-ttu-id="f3668-121">**越接近 1.00 越好**。</span><span class="sxs-lookup"><span data-stu-id="f3668-121">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="f3668-122">必須大於0.50，模型才會是可接受的。</span><span class="sxs-lookup"><span data-stu-id="f3668-122">It should be greater than 0.50 for a model to be acceptable.</span></span> <span data-ttu-id="f3668-123">AUC 為0.50 或更少的模型是不萬能。</span><span class="sxs-lookup"><span data-stu-id="f3668-123">A model with AUC of 0.50 or less is worthless.</span></span> |
| <span data-ttu-id="f3668-124">**AUCPR**</span><span class="sxs-lookup"><span data-stu-id="f3668-124">**AUCPR**</span></span> | <span data-ttu-id="f3668-125">*精確度回收曲線曲線下*的[aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8)或面積：不平衡類別時的預測成功量值（高度扭曲的資料集）。</span><span class="sxs-lookup"><span data-stu-id="f3668-125">[aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) or *Area under the curve of a Precision-Recall curve*: Useful measure of success of prediction when the classes are imbalanced (highly skewed datasets).</span></span> |  <span data-ttu-id="f3668-126">**越接近 1.00 越好**。</span><span class="sxs-lookup"><span data-stu-id="f3668-126">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="f3668-127">接近 1.00 的高分顯示分類器傳回精確的結果 (高精確度)，並傳回大部分為全面肯定的結果 (高重新叫用率)。</span><span class="sxs-lookup"><span data-stu-id="f3668-127">High scores close to 1.00 show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).</span></span> |
| <span data-ttu-id="f3668-128">**F1 分數**</span><span class="sxs-lookup"><span data-stu-id="f3668-128">**F1-score**</span></span> | <span data-ttu-id="f3668-129">[F1 分數](https://en.wikipedia.org/wiki/F1_score)也稱為「平衡 F 分數或 F 量值」。</span><span class="sxs-lookup"><span data-stu-id="f3668-129">[F1 score](https://en.wikipedia.org/wiki/F1_score) also known as *balanced F-score or F-measure*.</span></span> <span data-ttu-id="f3668-130">它是精確度和重新叫用率的調和平均數。</span><span class="sxs-lookup"><span data-stu-id="f3668-130">It's the harmonic mean of the precision and recall.</span></span> <span data-ttu-id="f3668-131">當您想要在精確度與重新叫用率之間取得平衡時，F1 分數會很有幫助。</span><span class="sxs-lookup"><span data-stu-id="f3668-131">F1 Score is helpful when you want to seek a balance between Precision and Recall.</span></span>| <span data-ttu-id="f3668-132">**越接近 1.00 越好**。</span><span class="sxs-lookup"><span data-stu-id="f3668-132">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="f3668-133">F1 分數在 1.00 達到其最佳值，而最差分數為 0.00。</span><span class="sxs-lookup"><span data-stu-id="f3668-133">An F1 score reaches its best value at 1.00 and worst score at 0.00.</span></span> <span data-ttu-id="f3668-134">它會告訴您分類器有多精確。</span><span class="sxs-lookup"><span data-stu-id="f3668-134">It tells you how precise your classifier is.</span></span> |

<span data-ttu-id="f3668-135">如需二元分類計量的進一步詳細資訊，請閱讀下列文章：</span><span class="sxs-lookup"><span data-stu-id="f3668-135">For further details on binary classification metrics read the following articles:</span></span>

- [<span data-ttu-id="f3668-136">精確度、精確度、召回率或 F1？</span><span class="sxs-lookup"><span data-stu-id="f3668-136">Accuracy, Precision, Recall, or F1?</span></span>](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)
- <span data-ttu-id="f3668-137">[BinaryClassificationMetrics Class](xref:Microsoft.ML.Data.BinaryClassificationMetrics) (BinaryClassificationMetrics 類別)</span><span class="sxs-lookup"><span data-stu-id="f3668-137">[Binary Classification Metrics class](xref:Microsoft.ML.Data.BinaryClassificationMetrics)</span></span>
- <span data-ttu-id="f3668-138">[The Relationship Between Precision-Recall and ROC Curves](http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf) (PR 曲線與 ROC 曲線之間的關聯性)</span><span class="sxs-lookup"><span data-stu-id="f3668-138">[The Relationship Between Precision-Recall and ROC Curves](http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf)</span></span>

## <a name="evaluation-metrics-for-multi-class-classification"></a><span data-ttu-id="f3668-139">多類別分類的評估計量</span><span class="sxs-lookup"><span data-stu-id="f3668-139">Evaluation metrics for Multi-class Classification</span></span>

| <span data-ttu-id="f3668-140">計量</span><span class="sxs-lookup"><span data-stu-id="f3668-140">Metrics</span></span>   |      <span data-ttu-id="f3668-141">描述</span><span class="sxs-lookup"><span data-stu-id="f3668-141">Description</span></span>      |  <span data-ttu-id="f3668-142">尋找 [程式和功能] 中所列的</span><span class="sxs-lookup"><span data-stu-id="f3668-142">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="f3668-143">**微準確度**</span><span class="sxs-lookup"><span data-stu-id="f3668-143">**Micro-Accuracy**</span></span> |  <span data-ttu-id="f3668-144">[微平均準確度](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy)彙總所有類別的比重來計算平均計量。</span><span class="sxs-lookup"><span data-stu-id="f3668-144">[Micro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) aggregates the contributions of all classes to compute the average metric.</span></span> <span data-ttu-id="f3668-145">它是正確預測的執行個體分數。</span><span class="sxs-lookup"><span data-stu-id="f3668-145">It is the fraction of instances predicted correctly.</span></span> <span data-ttu-id="f3668-146">微平均不會將類別成員資格納入考量。</span><span class="sxs-lookup"><span data-stu-id="f3668-146">The micro-average does not take class membership into account.</span></span> <span data-ttu-id="f3668-147">基本上，每個樣本類別配對佔準確度計量的比重會相等。</span><span class="sxs-lookup"><span data-stu-id="f3668-147">Basically, every sample-class pair contributes equally to the accuracy metric.</span></span> | <span data-ttu-id="f3668-148">**越接近 1.00 越好**。</span><span class="sxs-lookup"><span data-stu-id="f3668-148">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="f3668-149">在多元分類工作中，如果您懷疑類別失衡 (例如</span><span class="sxs-lookup"><span data-stu-id="f3668-149">In a multi-class classification task, micro-accuracy is preferable over macro-accuracy if you suspect there might be class imbalance (i.e</span></span> <span data-ttu-id="f3668-150">您擁有某個類別的範例數比其他類別的範例數更多)，則微準確度優於宏準確度。</span><span class="sxs-lookup"><span data-stu-id="f3668-150">you may have many more examples of one class than of other classes).</span></span>|
| <span data-ttu-id="f3668-151">**宏準確度**</span><span class="sxs-lookup"><span data-stu-id="f3668-151">**Macro-Accuracy**</span></span> | <span data-ttu-id="f3668-152">[宏平均準確度](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy)是類別層級的平均準確度。</span><span class="sxs-lookup"><span data-stu-id="f3668-152">[Macro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) is the average accuracy at the class level.</span></span> <span data-ttu-id="f3668-153">每個類別的準確度會經過計算，而宏準確度是這些準確度的平均。</span><span class="sxs-lookup"><span data-stu-id="f3668-153">The accuracy for each class is computed and the macro-accuracy is the average of these accuracies.</span></span> <span data-ttu-id="f3668-154">基本上，每個類別佔準確度計量的比重會相等。</span><span class="sxs-lookup"><span data-stu-id="f3668-154">Basically, every class contributes equally to the accuracy metric.</span></span> <span data-ttu-id="f3668-155">少數類別會加上與較大類別相同的權重。</span><span class="sxs-lookup"><span data-stu-id="f3668-155">Minority classes are given equal weight as the larger classes.</span></span> <span data-ttu-id="f3668-156">宏平均計量為每個類別提供相同的權數，無論資料集包含該類別中多少執行個體。</span><span class="sxs-lookup"><span data-stu-id="f3668-156">The macro-average metric gives the same weight to each class, no matter how many instances from that class the dataset contains.</span></span> |  <span data-ttu-id="f3668-157">**越接近 1.00 越好**。</span><span class="sxs-lookup"><span data-stu-id="f3668-157">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="f3668-158">它會單獨計算每個類別的計量，然後求其平均 (因此對所有類別一視同仁)</span><span class="sxs-lookup"><span data-stu-id="f3668-158">It computes the metric independently for each class and then takes the average (hence treating all classes equally)</span></span> |
| <span data-ttu-id="f3668-159">**對數損失**</span><span class="sxs-lookup"><span data-stu-id="f3668-159">**Log-loss**</span></span>| <span data-ttu-id="f3668-160">[對數損失](http://wiki.fast.ai/index.php/Log_Loss)測量分類模型的效能，其中預測輸入是介於 0.00 到 1.00 之間的機率值。</span><span class="sxs-lookup"><span data-stu-id="f3668-160">[Logarithmic loss](http://wiki.fast.ai/index.php/Log_Loss) measures the performance of a classification model where the prediction input is a probability value between 0.00 and 1.00.</span></span> <span data-ttu-id="f3668-161">對數損失會隨著預測機率與實際標籤的偏離而增加。</span><span class="sxs-lookup"><span data-stu-id="f3668-161">Log-loss increases as the predicted probability diverges from the actual label.</span></span> | <span data-ttu-id="f3668-162">**越接近 0.00 越好**。</span><span class="sxs-lookup"><span data-stu-id="f3668-162">**The closer to 0.00, the better**.</span></span> <span data-ttu-id="f3668-163">完美模型的對數損失值為 0.00。</span><span class="sxs-lookup"><span data-stu-id="f3668-163">A perfect model would have a log-loss of 0.00.</span></span> <span data-ttu-id="f3668-164">我們的機器學習模型目標是將此值降到最低。</span><span class="sxs-lookup"><span data-stu-id="f3668-164">The goal of our machine learning models is to minimize this value.</span></span>|
| <span data-ttu-id="f3668-165">**對數損失降低**</span><span class="sxs-lookup"><span data-stu-id="f3668-165">**Log-Loss Reduction**</span></span> | <span data-ttu-id="f3668-166">[對數損失降低](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction)可解譯為分類器優於隨機預測。</span><span class="sxs-lookup"><span data-stu-id="f3668-166">[Logarithmic loss reduction](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) can be interpreted as the advantage of the classifier over a random prediction.</span></span>| <span data-ttu-id="f3668-167">**範圍介於 -inf 到 1.00 之間，其中 1.00 表示完美的預測，而 0.00 表示平均預測**。</span><span class="sxs-lookup"><span data-stu-id="f3668-167">**Ranges from -inf and 1.00, where 1.00 is perfect predictions and 0.00 indicates mean predictions**.</span></span> <span data-ttu-id="f3668-168">例如，如果值等於 0.20，則可以解譯為「正確預測的機率比隨機猜測好 20%」</span><span class="sxs-lookup"><span data-stu-id="f3668-168">For example, if the value equals 0.20, it can be interpreted as "the probability of a correct prediction is 20% better than random guessing"</span></span>|

<span data-ttu-id="f3668-169">微準確度通常更符合 ML 預測的商務需求。</span><span class="sxs-lookup"><span data-stu-id="f3668-169">Micro-accuracy is generally better aligned with the business needs of ML predictions.</span></span> <span data-ttu-id="f3668-170">如果您想要選取單一計量來選擇多元分類工作品質，通常應該是微準確度。</span><span class="sxs-lookup"><span data-stu-id="f3668-170">If you want to select a single metric for choosing the quality of a multiclass classification task, it should usually be micro-accuracy.</span></span>

<span data-ttu-id="f3668-171">支援票證分類工作範例 (將傳入票證對應至支援小組)</span><span class="sxs-lookup"><span data-stu-id="f3668-171">Example, for a support ticket classification task: (maps incoming tickets to support teams)</span></span>

- <span data-ttu-id="f3668-172">微準確度 -- 傳入票證分類到正確小組的頻率為何？</span><span class="sxs-lookup"><span data-stu-id="f3668-172">Micro-accuracy -- how often does an incoming ticket get classified to the right team?</span></span>
- <span data-ttu-id="f3668-173">宏準確度 -- 對於一個普通小組而言，傳入票證對其小組正確的頻率為何？</span><span class="sxs-lookup"><span data-stu-id="f3668-173">Macro-accuracy -- for an average team, how often is an incoming ticket correct for their team?</span></span>

<span data-ttu-id="f3668-174">在此範例中，overweights 小型小組的宏精確度：每年僅取得10個票證的小型小組，其數量會與每年有10k 個票證的大型團隊一樣。</span><span class="sxs-lookup"><span data-stu-id="f3668-174">Macro-accuracy overweights small teams in this example; a small team that gets only 10 tickets per year counts as much as a large team with 10k tickets per year.</span></span> <span data-ttu-id="f3668-175">在此案例中，微準確度與「公司將我的票證路由程序最佳化可省下多少時間/金錢」的商務需求較相關。</span><span class="sxs-lookup"><span data-stu-id="f3668-175">Micro-accuracy in this case correlates better with the business need of, "how much time/money can the company save by automating my ticket routing process".</span></span>

<span data-ttu-id="f3668-176">如需多元分類計量的進一步詳細資訊，請閱讀下列文章：</span><span class="sxs-lookup"><span data-stu-id="f3668-176">For further details on multi-class classification metrics read the following articles:</span></span>

- [<span data-ttu-id="f3668-177">精確度、召回率和 F 分數的微和宏平均值</span><span class="sxs-lookup"><span data-stu-id="f3668-177">Micro- and Macro-average of Precision, Recall, and F-Score</span></span>](https://rushdishams.blogspot.com/2011/08/micro-and-macro-average-of-precision.html)
- <span data-ttu-id="f3668-178">[Multiclass Classification with Imbalanced Dataset](https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a) (失衡資料集的多元分類)</span><span class="sxs-lookup"><span data-stu-id="f3668-178">[Multiclass Classification with Imbalanced Dataset](https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a)</span></span>

## <a name="evaluation-metrics-for-regression-and-recommendation"></a><span data-ttu-id="f3668-179">回歸和建議的評估計量</span><span class="sxs-lookup"><span data-stu-id="f3668-179">Evaluation metrics for Regression and Recommendation</span></span>

<span data-ttu-id="f3668-180">回歸和建議工作都會預測數位。</span><span class="sxs-lookup"><span data-stu-id="f3668-180">Both the regression and recommendation tasks predict a number.</span></span> <span data-ttu-id="f3668-181">在回歸的情況下，此數目可以是任何受輸入屬性影響的輸出屬性。</span><span class="sxs-lookup"><span data-stu-id="f3668-181">In the case of regression, the number can be any output property that is influenced by the input properties.</span></span> <span data-ttu-id="f3668-182">針對建議，此數位通常是評等值（例如，介於1到5之間），或為 [是/否] 建議（分別以1和0表示）。</span><span class="sxs-lookup"><span data-stu-id="f3668-182">For recommendation, the number is usually a rating value (between 1 and 5 for example), or a yes/no recommendation (represented by 1 and 0 respectively).</span></span>

| <span data-ttu-id="f3668-183">度量</span><span class="sxs-lookup"><span data-stu-id="f3668-183">Metric</span></span>   |      <span data-ttu-id="f3668-184">描述</span><span class="sxs-lookup"><span data-stu-id="f3668-184">Description</span></span>      |  <span data-ttu-id="f3668-185">尋找 [程式和功能] 中所列的</span><span class="sxs-lookup"><span data-stu-id="f3668-185">Look for</span></span> |
|----------|-----------------------|-----------|
| <span data-ttu-id="f3668-186">**R 平方**</span><span class="sxs-lookup"><span data-stu-id="f3668-186">**R-Squared**</span></span> |  <span data-ttu-id="f3668-187">[R 平方 (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination) 或「決定係數」以介於 -inf 到 1.00 之間的值來表示模型的預測能力。</span><span class="sxs-lookup"><span data-stu-id="f3668-187">[R-squared (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination), or *Coefficient of determination* represents the predictive power of the model as a value between -inf and 1.00.</span></span> <span data-ttu-id="f3668-188">1.00 表示有完全擬合；擬合也可能很差，因此分數可以是負數。</span><span class="sxs-lookup"><span data-stu-id="f3668-188">1.00 means there is a perfect fit, and the fit can be arbitrarily poor so the scores can be negative.</span></span> <span data-ttu-id="f3668-189">分數 0.00 表示模型將猜測到標籤的預測值。</span><span class="sxs-lookup"><span data-stu-id="f3668-189">A score of 0.00 means the model is guessing the expected value for the label.</span></span> <span data-ttu-id="f3668-190">R2 測量實際測試資料值與預測值有多接近。</span><span class="sxs-lookup"><span data-stu-id="f3668-190">R2 measures how close the actual test data values are to the predicted values.</span></span> | <span data-ttu-id="f3668-191">**越接近 1.00，品質就越好**。</span><span class="sxs-lookup"><span data-stu-id="f3668-191">**The closer to 1.00, the better quality**.</span></span> <span data-ttu-id="f3668-192">不過，有時低 R 平方值 (例如 0.50) 可能完全正常或適合您的情節，而高 R 平方值不一定良好且值得懷疑。</span><span class="sxs-lookup"><span data-stu-id="f3668-192">However, sometimes low R-squared values (such as 0.50) can be entirely normal or good enough for your scenario and high R-squared values are not always good and be suspicious.</span></span> |
| <span data-ttu-id="f3668-193">**絕對損失**</span><span class="sxs-lookup"><span data-stu-id="f3668-193">**Absolute-loss**</span></span> |  <span data-ttu-id="f3668-194">[絕對損失](https://en.wikipedia.org/wiki/Mean_absolute_error)或「平均絕對誤差 (MAE)」測量預測與實際結果有多接近。</span><span class="sxs-lookup"><span data-stu-id="f3668-194">[Absolute-loss](https://en.wikipedia.org/wiki/Mean_absolute_error) or *Mean absolute error (MAE)* measures how close the predictions are to the actual outcomes.</span></span> <span data-ttu-id="f3668-195">它是所有模型誤差的平均，其中模型誤差係指所預測標籤值與正確標籤值之間的絕對差。</span><span class="sxs-lookup"><span data-stu-id="f3668-195">It is the average of all the model errors, where model error is the absolute distance between the predicted label value and the correct label value.</span></span> <span data-ttu-id="f3668-196">此預測誤差是針對每個記錄到的測試資料集計算而來。</span><span class="sxs-lookup"><span data-stu-id="f3668-196">This prediction error is calculated for each record of the test data set.</span></span> <span data-ttu-id="f3668-197">最後，會針對所有記錄到的絕對誤差，計算其平均值。</span><span class="sxs-lookup"><span data-stu-id="f3668-197">Finally, the mean value is calculated for all recorded absolute errors.</span></span>| <span data-ttu-id="f3668-198">**越接近 0.00，品質就越好。**</span><span class="sxs-lookup"><span data-stu-id="f3668-198">**The closer to 0.00, the better quality.**</span></span> <span data-ttu-id="f3668-199">平均絕對錯誤會使用與所測量資料相同的小數值（不會正規化為特定範圍）。</span><span class="sxs-lookup"><span data-stu-id="f3668-199">The mean absolute error uses the same scale as the data being measured (is not normalized to specific range).</span></span> <span data-ttu-id="f3668-200">只有模型屬於相同資料集或標籤值分佈類似的資料集時，才能使用絕對損失、平方損失和 RMS 損失以在這些模型之間進行比較。</span><span class="sxs-lookup"><span data-stu-id="f3668-200">Absolute-loss, Squared-loss, and RMS-loss can only be used to make comparisons between models for the same dataset or dataset with a similar label value distribution.</span></span> |
| <span data-ttu-id="f3668-201">**平方損失**</span><span class="sxs-lookup"><span data-stu-id="f3668-201">**Squared-loss**</span></span> |  <span data-ttu-id="f3668-202">[[方形-遺失](https://en.wikipedia.org/wiki/Mean_squared_error)] 或 [ *mean 平方誤差（MSE）* ] 也稱為 [*平均平方差（MSD）* ]，告訴您如何將迴歸線與一組測試資料值進行比對，方法是將點距離迴歸線（這些距離為「錯誤」 E）並加以求差。</span><span class="sxs-lookup"><span data-stu-id="f3668-202">[Squared-loss](https://en.wikipedia.org/wiki/Mean_squared_error) or *Mean Squared Error (MSE)*, also called *Mean Squared Deviation (MSD)*, tells you how close a regression line is to a set of test data values by taking the distances from the points to the regression line (these distances are the errors E) and squaring them.</span></span> <span data-ttu-id="f3668-203">平方會提供較多權數給較大的偏差。</span><span class="sxs-lookup"><span data-stu-id="f3668-203">The squaring gives more weight to larger differences.</span></span> | <span data-ttu-id="f3668-204">它一律是非負數，且**值越接近 0.00 越好**。</span><span class="sxs-lookup"><span data-stu-id="f3668-204">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="f3668-205">視您的資料而定，可能無法取得非常小的均方誤差值。</span><span class="sxs-lookup"><span data-stu-id="f3668-205">Depending on your data, it may be impossible to get a very small value for the mean squared error.</span></span>|
| <span data-ttu-id="f3668-206">**RMS 損失**</span><span class="sxs-lookup"><span data-stu-id="f3668-206">**RMS-loss**</span></span> |  <span data-ttu-id="f3668-207">[RMS 遺失](https://en.wikipedia.org/wiki/Root-mean-square_deviation)或*根平均平方誤差（RMSE）* （也稱為「*根平均平方偏差*」（RMSD）），測量由模型預測的值與所模型化環境中觀察到的值之間的差異。</span><span class="sxs-lookup"><span data-stu-id="f3668-207">[RMS-loss](https://en.wikipedia.org/wiki/Root-mean-square_deviation) or *Root Mean Squared Error (RMSE)* (also called *Root Mean Square Deviation, RMSD*), measures the difference between values predicted by a model and the values observed from the environment that is being modeled.</span></span> <span data-ttu-id="f3668-208">RMS 損失是平方損失的平方根，且具有與標籤相同的單位，類似於絕對損失，但提供較多權數給較大的偏差。</span><span class="sxs-lookup"><span data-stu-id="f3668-208">RMS-loss is the square root of Squared-loss and has the same units as the label, similar to the absolute-loss though giving more weight to larger differences.</span></span> <span data-ttu-id="f3668-209">均方根誤差常用於氣候學、預測和迴歸分析來驗證實驗結果。</span><span class="sxs-lookup"><span data-stu-id="f3668-209">Root mean square error is commonly used in climatology, forecasting, and regression analysis to verify experimental results.</span></span> | <span data-ttu-id="f3668-210">它一律是非負數，且**值越接近 0.00 越好**。</span><span class="sxs-lookup"><span data-stu-id="f3668-210">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="f3668-211">RMSD 是準確度量值，用於比較特定資料集 (而非資料集之間) 不同模型的預測誤差，因為它會視標尺而定。</span><span class="sxs-lookup"><span data-stu-id="f3668-211">RMSD is a measure of accuracy, to compare forecasting errors of different models for a particular dataset and not between datasets, as it is scale-dependent.</span></span>|

<span data-ttu-id="f3668-212">如需迴歸計量的進一步詳細資訊，請閱讀下列文章：</span><span class="sxs-lookup"><span data-stu-id="f3668-212">For further details on regression metrics, read the following articles:</span></span>

- [<span data-ttu-id="f3668-213">迴歸分析：如何解讀 R 平方並評估其適用性？</span><span class="sxs-lookup"><span data-stu-id="f3668-213">Regression Analysis: How Do I Interpret R-squared and Assess the Goodness-of-Fit?</span></span>](https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit)
- <span data-ttu-id="f3668-214">[How To Interpret R-squared in Regression Analysis](https://statisticsbyjim.com/regression/interpret-r-squared-regression) (如何解譯迴歸分析中的 R 平方)</span><span class="sxs-lookup"><span data-stu-id="f3668-214">[How To Interpret R-squared in Regression Analysis](https://statisticsbyjim.com/regression/interpret-r-squared-regression)</span></span>
- <span data-ttu-id="f3668-215">[R-Squared Definition](https://www.investopedia.com/terms/r/r-squared.asp) (R 平方定義)</span><span class="sxs-lookup"><span data-stu-id="f3668-215">[R-Squared Definition](https://www.investopedia.com/terms/r/r-squared.asp)</span></span>
- <span data-ttu-id="f3668-216">[Mean Squared Error Definition](https://www.statisticshowto.datasciencecentral.com/mean-squared-error/) (均方誤差定義)</span><span class="sxs-lookup"><span data-stu-id="f3668-216">[Mean Squared Error Definition](https://www.statisticshowto.datasciencecentral.com/mean-squared-error/)</span></span>
- <span data-ttu-id="f3668-217">[What are Mean Squared Error and Root Mean Squared Error?](https://www.vernier.com/til/1014/) (什麼是均方誤差和均方根誤差？)</span><span class="sxs-lookup"><span data-stu-id="f3668-217">[What are Mean Squared Error and Root Mean Squared Error?](https://www.vernier.com/til/1014/)</span></span>

## <a name="evaluation-metrics-for-clustering"></a><span data-ttu-id="f3668-218">群集的評估計量</span><span class="sxs-lookup"><span data-stu-id="f3668-218">Evaluation metrics for Clustering</span></span>

| <span data-ttu-id="f3668-219">度量</span><span class="sxs-lookup"><span data-stu-id="f3668-219">Metric</span></span>   |      <span data-ttu-id="f3668-220">描述</span><span class="sxs-lookup"><span data-stu-id="f3668-220">Description</span></span>      |  <span data-ttu-id="f3668-221">尋找 [程式和功能] 中所列的</span><span class="sxs-lookup"><span data-stu-id="f3668-221">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="f3668-222">**平均距離**</span><span class="sxs-lookup"><span data-stu-id="f3668-222">**Average Distance**</span></span>|<span data-ttu-id="f3668-223">資料點和其指派叢集中心之間的平均距離。</span><span class="sxs-lookup"><span data-stu-id="f3668-223">Average of the distance between data points and the center of their assigned cluster.</span></span> <span data-ttu-id="f3668-224">平均距離是將資料點與叢集距心鄰近的量值。</span><span class="sxs-lookup"><span data-stu-id="f3668-224">The average distance is a measure of proximity of the data points to cluster centroids.</span></span> <span data-ttu-id="f3668-225">這是「緊密」叢集的測量方式。</span><span class="sxs-lookup"><span data-stu-id="f3668-225">It's a measure of how 'tight' the cluster is.</span></span>|<span data-ttu-id="f3668-226">接近**0**的值比較好。</span><span class="sxs-lookup"><span data-stu-id="f3668-226">Values closer to **0** are better.</span></span> <span data-ttu-id="f3668-227">接近零的平均距離是，資料的群集越多。</span><span class="sxs-lookup"><span data-stu-id="f3668-227">The closer to zero the average distance is, the more clustered the data is.</span></span> <span data-ttu-id="f3668-228">不過要注意的是，如果叢集數目增加，此計量就會減少，而且在極端情況下（每個不同的資料點都是它自己的叢集），它會等於零。</span><span class="sxs-lookup"><span data-stu-id="f3668-228">Note though, that this metric will decrease if the number of clusters is increased, and in the extreme case (where each distinct data point is its own cluster) it will be equal to zero.</span></span>
|<span data-ttu-id="f3668-229">**Davies Bouldin 索引**</span><span class="sxs-lookup"><span data-stu-id="f3668-229">**Davies Bouldin Index**</span></span>|<span data-ttu-id="f3668-230">內部叢集距離到叢集距離之間的平均比率。</span><span class="sxs-lookup"><span data-stu-id="f3668-230">The average ratio of within-cluster distances to between-cluster distances.</span></span> <span data-ttu-id="f3668-231">叢集愈緊密，而叢集越進一步，此值就越低。</span><span class="sxs-lookup"><span data-stu-id="f3668-231">The tighter the cluster, and the further apart the clusters are, the lower this value is.</span></span>|<span data-ttu-id="f3668-232">接近**0**的值比較好。</span><span class="sxs-lookup"><span data-stu-id="f3668-232">Values closer to **0** are better.</span></span> <span data-ttu-id="f3668-233">較不分散且未散佈的叢集將會產生較佳的分數。</span><span class="sxs-lookup"><span data-stu-id="f3668-233">Clusters that are farther apart and less dispersed will result in a better score.</span></span>|
|<span data-ttu-id="f3668-234">**正規化的相互資訊**</span><span class="sxs-lookup"><span data-stu-id="f3668-234">**Normalized Mutual Information**</span></span>|<span data-ttu-id="f3668-235">當用來定型群集模型的定型資料也隨附于真標籤（也就是受監督的叢集）時，可以使用。</span><span class="sxs-lookup"><span data-stu-id="f3668-235">Can be used when the training data used to train the clustering model also comes with ground truth labels (that is, supervised clustering).</span></span> <span data-ttu-id="f3668-236">正規化的相互資訊計量會測量是否將類似的資料點指派給相同的叢集，並將不同的資料點指派給不同的群集。</span><span class="sxs-lookup"><span data-stu-id="f3668-236">The Normalized Mutual Information metric measures whether similar data points get assigned to the same cluster and disparate data points get assigned to different clusters.</span></span> <span data-ttu-id="f3668-237">正規化的相互資訊是介於0和1之間的值</span><span class="sxs-lookup"><span data-stu-id="f3668-237">Normalized mutual information is a value between 0 and 1</span></span>|<span data-ttu-id="f3668-238">接近**1**的值比較好</span><span class="sxs-lookup"><span data-stu-id="f3668-238">Values closer to **1** are better</span></span>|

## <a name="evaluation-metrics-for-ranking"></a><span data-ttu-id="f3668-239">排名的評估計量</span><span class="sxs-lookup"><span data-stu-id="f3668-239">Evaluation metrics for Ranking</span></span>

| <span data-ttu-id="f3668-240">度量</span><span class="sxs-lookup"><span data-stu-id="f3668-240">Metric</span></span>   |      <span data-ttu-id="f3668-241">描述</span><span class="sxs-lookup"><span data-stu-id="f3668-241">Description</span></span>      |  <span data-ttu-id="f3668-242">尋找 [程式和功能] 中所列的</span><span class="sxs-lookup"><span data-stu-id="f3668-242">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="f3668-243">**折扣的累計增益**</span><span class="sxs-lookup"><span data-stu-id="f3668-243">**Discounted Cumulative Gains**</span></span>|<span data-ttu-id="f3668-244">折扣累積增益（DCG）是排名品質的量值。</span><span class="sxs-lookup"><span data-stu-id="f3668-244">Discounted cumulative gain (DCG) is a measure of ranking quality.</span></span> <span data-ttu-id="f3668-245">它衍生自兩個假設。</span><span class="sxs-lookup"><span data-stu-id="f3668-245">It is derived from two assumptions.</span></span> <span data-ttu-id="f3668-246">一：高度相關的專案在按順位順序顯示較高時，會更有用。</span><span class="sxs-lookup"><span data-stu-id="f3668-246">One: Highly relevant items are more useful when appearing higher in ranking order.</span></span> <span data-ttu-id="f3668-247">二：實用性會追蹤相關性，也就是相關性越高，專案就越有用。</span><span class="sxs-lookup"><span data-stu-id="f3668-247">Two: Usefulness tracks relevance that is, the higher the relevance, the more useful an item.</span></span> <span data-ttu-id="f3668-248">折扣累計增益是針對次序順序中的特定位置計算而得。</span><span class="sxs-lookup"><span data-stu-id="f3668-248">Discounted cumulative gain is calculated for a particular position in the ranking order.</span></span> <span data-ttu-id="f3668-249">它會加總相關性評分除以順位索引到感利率的對數。</span><span class="sxs-lookup"><span data-stu-id="f3668-249">It sums the relevance grading divided by the logarithm of the ranking index up to the position of interest.</span></span> <span data-ttu-id="f3668-250">其計算方式是使用 $ \ sum_ {i = 0} ^ {p} \frac {rel_i} {\ log_ {e} {i + 1}} $ 相關性 gradings 提供給排名訓練演算法做為基礎標籤。</span><span class="sxs-lookup"><span data-stu-id="f3668-250">It is calculated using $\sum_{i=0}^{p} \frac {rel_i} {\log_{e}{i+1}}$ Relevance gradings are provided to a ranking training algorithm as ground truth labels.</span></span> <span data-ttu-id="f3668-251">針對排名資料表中的每個位置提供一個 DCG 值，因此名稱折扣累計**增益**。</span><span class="sxs-lookup"><span data-stu-id="f3668-251">One DCG value is provided for each position in the ranking table, hence the name Discounted Cumulative **Gains**.</span></span> |<span data-ttu-id="f3668-252">**較高的值愈好**</span><span class="sxs-lookup"><span data-stu-id="f3668-252">**Higher values are better**</span></span>|
|<span data-ttu-id="f3668-253">**標準化折扣累計增益**</span><span class="sxs-lookup"><span data-stu-id="f3668-253">**Normalized Discounted Cumulative Gains**</span></span>|<span data-ttu-id="f3668-254">正規化 DCG 允許將計量與不同長度的排名清單進行比較</span><span class="sxs-lookup"><span data-stu-id="f3668-254">Normalizing DCG allows the metric to be compared for ranking lists of different lengths</span></span>|<span data-ttu-id="f3668-255">**接近1的值比較好**</span><span class="sxs-lookup"><span data-stu-id="f3668-255">**Values closer to 1 are better**</span></span>|

## <a name="evaluation-metrics-for-anomaly-detection"></a><span data-ttu-id="f3668-256">異常偵測的評估計量</span><span class="sxs-lookup"><span data-stu-id="f3668-256">Evaluation metrics for Anomaly Detection</span></span>

| <span data-ttu-id="f3668-257">度量</span><span class="sxs-lookup"><span data-stu-id="f3668-257">Metric</span></span>   |      <span data-ttu-id="f3668-258">描述</span><span class="sxs-lookup"><span data-stu-id="f3668-258">Description</span></span>      |  <span data-ttu-id="f3668-259">尋找 [程式和功能] 中所列的</span><span class="sxs-lookup"><span data-stu-id="f3668-259">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="f3668-260">**ROC 曲線下的區域**</span><span class="sxs-lookup"><span data-stu-id="f3668-260">**Area Under ROC Curve**</span></span>|<span data-ttu-id="f3668-261">收件者運算子曲線下的區域會測量模型將異常和一般資料點分開的程度。</span><span class="sxs-lookup"><span data-stu-id="f3668-261">Area under the receiver operator curve measures how well the model separates anomalous and usual data points.</span></span>|<span data-ttu-id="f3668-262">**接近1的值比較好**。</span><span class="sxs-lookup"><span data-stu-id="f3668-262">**Values closer to 1 are better**.</span></span> <span data-ttu-id="f3668-263">只有大於0.5 的值才會示範模型的有效性。</span><span class="sxs-lookup"><span data-stu-id="f3668-263">Only values greater than 0.5 demonstrate effectiveness of the model.</span></span> <span data-ttu-id="f3668-264">0\.5 或以下的值表示模型不會將輸入隨機配置到異常和一般分類</span><span class="sxs-lookup"><span data-stu-id="f3668-264">Values of 0.5 or below indicate that the model is no better than randomly allocating the inputs to anomalous and usual categories</span></span>|
|<span data-ttu-id="f3668-265">**錯誤正面計數的偵測速率**</span><span class="sxs-lookup"><span data-stu-id="f3668-265">**Detection Rate At False Positive Count**</span></span>|<span data-ttu-id="f3668-266">錯誤正計數的偵測速率是已正確識別的異常數目與測試集的異常總數的比率（依每個錯誤的正數編制索引）。</span><span class="sxs-lookup"><span data-stu-id="f3668-266">Detection rate at false positive count is the ratio of the number of correctly identified anomalies to the total number of anomalies in a test set, indexed by each false positive.</span></span> <span data-ttu-id="f3668-267">也就是說，每個錯誤正面專案的 [偵測速率] 的值是 [假的正計數]。</span><span class="sxs-lookup"><span data-stu-id="f3668-267">That is, there is a value for detection rate at false positive count for each false positive item.</span></span>|<span data-ttu-id="f3668-268">**接近1的值比較好**。</span><span class="sxs-lookup"><span data-stu-id="f3668-268">**Values closer to 1 are better**.</span></span> <span data-ttu-id="f3668-269">如果沒有誤報，則此值為1。</span><span class="sxs-lookup"><span data-stu-id="f3668-269">If there are no false positives, then this value is 1</span></span>|
