---
title: 如何選擇 ML.NET 演算法
description: 了解如何選擇機器學習模型的 ML.NET 演算法
author: natke
ms.topic: overview
ms.date: 04/20/1029
ms.openlocfilehash: 3fd515a1d150ea51214b55f882726c4ba76bd6d1
ms.sourcegitcommit: ca2ca60e6f5ea327f164be7ce26d9599e0f85fe4
ms.translationtype: HT
ms.contentlocale: zh-TW
ms.lasthandoff: 05/06/2019
ms.locfileid: "65065631"
---
# <a name="how-to-choose-an-mlnet-algorithm"></a><span data-ttu-id="e8421-103">如何選擇 ML.NET 演算法</span><span class="sxs-lookup"><span data-stu-id="e8421-103">How to choose an ML.NET algorithm</span></span>

<span data-ttu-id="e8421-104">針對每項 [ML.NET 工作](resources/tasks.md)，有多個定型演算法可供選擇。</span><span class="sxs-lookup"><span data-stu-id="e8421-104">For each [ML.NET task](resources/tasks.md), there are multiple training algorithms to choose from.</span></span> <span data-ttu-id="e8421-105">要選擇哪一個，取決於您嘗試解決的問題、您資料的特性，以及您目前可使用的計算和儲存資源。</span><span class="sxs-lookup"><span data-stu-id="e8421-105">Which one to choose depends on the problem you are trying to solve, the characteristics of your data, and the compute and storage resources you have available.</span></span> <span data-ttu-id="e8421-106">請務必注意，定型的機器學習模型是一種反覆運算程序。</span><span class="sxs-lookup"><span data-stu-id="e8421-106">It is important to note that training a machine learning model is an iterative process.</span></span> <span data-ttu-id="e8421-107">您可能需要嘗試多種演算法，找出最適合的那一種。</span><span class="sxs-lookup"><span data-stu-id="e8421-107">You might need to try multiple algorithms to find the one that works best.</span></span>

<span data-ttu-id="e8421-108">演算法作用於**特性**。</span><span class="sxs-lookup"><span data-stu-id="e8421-108">Algorithms operate on **features**.</span></span> <span data-ttu-id="e8421-109">特性是計算輸入資料所得出的數值。</span><span class="sxs-lookup"><span data-stu-id="e8421-109">Features are numerical values computed from your input data.</span></span> <span data-ttu-id="e8421-110">它們是機器學習演算法的最佳輸入。</span><span class="sxs-lookup"><span data-stu-id="e8421-110">They are optimal inputs for machine learning algorithms.</span></span> <span data-ttu-id="e8421-111">您使用一或多種[資料轉換](resources/transforms.md)，將未經處理的輸入資料轉換成特性。</span><span class="sxs-lookup"><span data-stu-id="e8421-111">You transform your raw input data into features using one or more [data transforms](resources/transforms.md).</span></span> <span data-ttu-id="e8421-112">例如，文字資料會轉換成一組字數統計和字詞組合統計。</span><span class="sxs-lookup"><span data-stu-id="e8421-112">For example, text data is transformed into a set of word counts and word combination counts.</span></span> <span data-ttu-id="e8421-113">一旦使用資料轉換從未經處理的資料類型擷取特性，它們就稱為**凸顯**。</span><span class="sxs-lookup"><span data-stu-id="e8421-113">Once the features have been extracted from a raw data type using data transforms, they are referred to as **featurized**.</span></span> <span data-ttu-id="e8421-114">例如，凸顯的文字或影像資料。</span><span class="sxs-lookup"><span data-stu-id="e8421-114">For example, featurized text, or featurized image data.</span></span>

## <a name="trainer--algorithm--task"></a><span data-ttu-id="e8421-115">定型器 = 演算法 + 工作</span><span class="sxs-lookup"><span data-stu-id="e8421-115">Trainer = Algorithm + Task</span></span>

<span data-ttu-id="e8421-116">演算法是為產生**模型**所執行的數學。</span><span class="sxs-lookup"><span data-stu-id="e8421-116">An algorithm is the math that executes to produce a **model**.</span></span> <span data-ttu-id="e8421-117">不同演算法產生不同特性的模型。</span><span class="sxs-lookup"><span data-stu-id="e8421-117">Different algorithms produce models with different characteristics.</span></span> 

<span data-ttu-id="e8421-118">使用 ML.NET，相同演算法可以套用到不同的工作。</span><span class="sxs-lookup"><span data-stu-id="e8421-118">With ML.NET, the same algorithm can be applied to different tasks.</span></span> <span data-ttu-id="e8421-119">例如，隨機對偶座標上升法可用於二元分類、多元分類和迴歸。</span><span class="sxs-lookup"><span data-stu-id="e8421-119">For example, Stochastic Descent Coordinated Ascent can be used for Binary Classification, Multiclass Classification, and Regression.</span></span> <span data-ttu-id="e8421-120">不同之處在於如何解譯演算法的輸出，使符合工作。</span><span class="sxs-lookup"><span data-stu-id="e8421-120">The difference is in how the output of the algorithm is interpreted to match the task.</span></span> 

<span data-ttu-id="e8421-121">針對每種演算法/工作組合，ML.NET 提供執行定型演算法和完成解譯的元件。</span><span class="sxs-lookup"><span data-stu-id="e8421-121">For each algorithm/task combination, ML.NET provides a component that executes the training algorithm and does the interpretation.</span></span> <span data-ttu-id="e8421-122">這些元件稱為「定型器」。</span><span class="sxs-lookup"><span data-stu-id="e8421-122">These components are called trainers.</span></span> <span data-ttu-id="e8421-123">例如，<xref:Microsoft.ML.Trainers.SdcaRegressionTrainer> 使用 **StochasticDualCoordinatedAscent** 演算法套用至**迴歸**工作。</span><span class="sxs-lookup"><span data-stu-id="e8421-123">For example, the <xref:Microsoft.ML.Trainers.SdcaRegressionTrainer> uses the **StochasticDualCoordinatedAscent** algorithm applied to the **Regression** task.</span></span>

## <a name="linear-algorithms"></a><span data-ttu-id="e8421-124">線性演算法</span><span class="sxs-lookup"><span data-stu-id="e8421-124">Linear algorithms</span></span>

<span data-ttu-id="e8421-125">線性演算法產生的模型會計算輸入資料和一組**權數**之線性組合的**分數**。</span><span class="sxs-lookup"><span data-stu-id="e8421-125">Linear algorithms produce a model that calculates **scores** from a linear combination of the input data and a set of **weights**.</span></span> <span data-ttu-id="e8421-126">權數是在定型期間評估的模型參數。</span><span class="sxs-lookup"><span data-stu-id="e8421-126">The weights are parameters of the model estimated during training.</span></span>

<span data-ttu-id="e8421-127">線性演算法適用於[線性可分](https://en.wikipedia.org/wiki/Linear_separability)的特性。</span><span class="sxs-lookup"><span data-stu-id="e8421-127">Linear algorithms work well for features that are [linearly separable](https://en.wikipedia.org/wiki/Linear_separability).</span></span>

<span data-ttu-id="e8421-128">使用線性演算法定型之前，應先將特性標準化。</span><span class="sxs-lookup"><span data-stu-id="e8421-128">Before training with a linear algorithm, the features should be normalized.</span></span> <span data-ttu-id="e8421-129">這可防止某項特色對結果的影響超過其他特色。</span><span class="sxs-lookup"><span data-stu-id="e8421-129">This prevents one feature having more influence over the result than others.</span></span>

<span data-ttu-id="e8421-130">一般而言，線性演算法可調整又快速，定型和預測的成本低廉。</span><span class="sxs-lookup"><span data-stu-id="e8421-130">In general linear algorithms are scalable and fast, cheap to train, cheap to predict.</span></span> <span data-ttu-id="e8421-131">它們可以調整特色數目，約為定型資料集的大小。</span><span class="sxs-lookup"><span data-stu-id="e8421-131">They scale by the number of features and approximately by the size of the training data set.</span></span>

<span data-ttu-id="e8421-132">線性演算法對定型資料進行多次傳遞。</span><span class="sxs-lookup"><span data-stu-id="e8421-132">Linear algorithms make multiple passes over the training data.</span></span> <span data-ttu-id="e8421-133">如果您的資料集貼合記憶體，則先將[快取檢查點](xref:Microsoft.ML.LearningPipelineExtensions.AppendCacheCheckpoint*)新增至 ML.NET 管線，再附加定型器，會讓定型執行更快速。</span><span class="sxs-lookup"><span data-stu-id="e8421-133">If your dataset fits into memory, then adding a [cache checkpoint](xref:Microsoft.ML.LearningPipelineExtensions.AppendCacheCheckpoint*) to your ML.NET pipeline before appending the trainer, will make the training run faster.</span></span>

<span data-ttu-id="e8421-134">**線性定型器**</span><span class="sxs-lookup"><span data-stu-id="e8421-134">**Linear Trainers**</span></span>

|<span data-ttu-id="e8421-135">演算法</span><span class="sxs-lookup"><span data-stu-id="e8421-135">Algorithm</span></span>|<span data-ttu-id="e8421-136">屬性</span><span class="sxs-lookup"><span data-stu-id="e8421-136">Properties</span></span>|<span data-ttu-id="e8421-137">定型器</span><span class="sxs-lookup"><span data-stu-id="e8421-137">Trainers</span></span>|
|---------|----------|--------|
|<span data-ttu-id="e8421-138">平均感知器</span><span class="sxs-lookup"><span data-stu-id="e8421-138">Averaged perceptron</span></span>|<span data-ttu-id="e8421-139">最適合文字分類</span><span class="sxs-lookup"><span data-stu-id="e8421-139">Best for text classification</span></span>|<xref:Microsoft.ML.Trainers.AveragedPerceptronTrainer>|
|<span data-ttu-id="e8421-140">隨機對偶座標上升法</span><span class="sxs-lookup"><span data-stu-id="e8421-140">Stochastic descent coordinated ascent</span></span>|<span data-ttu-id="e8421-141">好的預設效能不需要微調</span><span class="sxs-lookup"><span data-stu-id="e8421-141">Tuning not needed for good default performance</span></span>|<span data-ttu-id="e8421-142"><xref:Microsoft.ML.Trainers.SdcaLogisticRegressionBinaryTrainer> <xref:Microsoft.ML.Trainers.SdcaNonCalibratedBinaryTrainer> <xref:Microsoft.ML.Trainers.SdcaMaximumEntropyMulticlassTrainer> <xref:Microsoft.ML.Trainers.SdcaNonCalibratedMulticlassTrainer> <xref:Microsoft.ML.Trainers.SdcaRegressionTrainer></span><span class="sxs-lookup"><span data-stu-id="e8421-142"><xref:Microsoft.ML.Trainers.SdcaLogisticRegressionBinaryTrainer> <xref:Microsoft.ML.Trainers.SdcaNonCalibratedBinaryTrainer> <xref:Microsoft.ML.Trainers.SdcaMaximumEntropyMulticlassTrainer> <xref:Microsoft.ML.Trainers.SdcaNonCalibratedMulticlassTrainer> <xref:Microsoft.ML.Trainers.SdcaRegressionTrainer></span></span>|
|<span data-ttu-id="e8421-143">L-BFGS</span><span class="sxs-lookup"><span data-stu-id="e8421-143">L-BFGS</span></span>|<span data-ttu-id="e8421-144">當特性數目很大時使用。</span><span class="sxs-lookup"><span data-stu-id="e8421-144">Use when number of features is large.</span></span> <span data-ttu-id="e8421-145">產生羅吉斯迴歸定型統計資料，但不像 AveragedPerceptronTrainer 縮放自如</span><span class="sxs-lookup"><span data-stu-id="e8421-145">Produces logistic regression training statistics, but doesn't scale as well as the AveragedPerceptronTrainer</span></span>|<span data-ttu-id="e8421-146"><xref:Microsoft.ML.Trainers.LbfgsLogisticRegressionBinaryTrainer> <xref:Microsoft.ML.Trainers.LbfgsMaximumEntropyMulticlassTrainer> <xref:Microsoft.ML.Trainers.LbfgsPoissonRegressionTrainer></span><span class="sxs-lookup"><span data-stu-id="e8421-146"><xref:Microsoft.ML.Trainers.LbfgsLogisticRegressionBinaryTrainer> <xref:Microsoft.ML.Trainers.LbfgsMaximumEntropyMulticlassTrainer> <xref:Microsoft.ML.Trainers.LbfgsPoissonRegressionTrainer></span></span>|
|<span data-ttu-id="e8421-147">符號隨機梯度下降</span><span class="sxs-lookup"><span data-stu-id="e8421-147">Symbolic stochastic gradient descent</span></span>|<span data-ttu-id="e8421-148">最快速且最精確的線性二元分類定型器。</span><span class="sxs-lookup"><span data-stu-id="e8421-148">Fastest and most accurate linear binary classification trainer.</span></span> <span data-ttu-id="e8421-149">可隨處理器數目調整</span><span class="sxs-lookup"><span data-stu-id="e8421-149">Scales well with number of processors</span></span>|<xref:Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer>|

## <a name="decision-tree-algorithms"></a><span data-ttu-id="e8421-150">決策樹演算法</span><span class="sxs-lookup"><span data-stu-id="e8421-150">Decision tree algorithms</span></span>

<span data-ttu-id="e8421-151">決策樹演算法建立的模型，包含一系列的決策：所有資料值的有效流程圖。</span><span class="sxs-lookup"><span data-stu-id="e8421-151">Decision tree algorithms create a model that contains a series of decisions: effectively a flow chart through the data values.</span></span>

<span data-ttu-id="e8421-152">特性不需要為線性可分，也可以使用這種演算法。</span><span class="sxs-lookup"><span data-stu-id="e8421-152">Features do not need to be linearly separable to use this type of algorithm.</span></span> <span data-ttu-id="e8421-153">而且特性不需要標準化，因為在決策流程中會單獨使用特性向量的個別值。</span><span class="sxs-lookup"><span data-stu-id="e8421-153">And features do not need to be normalized, because the individual values in the feature vector are used independently in the decision process.</span></span>

<span data-ttu-id="e8421-154">決策樹演算法通常非常精確。</span><span class="sxs-lookup"><span data-stu-id="e8421-154">Decision tree algorithms are generally very accurate.</span></span>

<span data-ttu-id="e8421-155">除了一般化累加模型 (GAM) 外，樹狀模型在特性數目很大時會欠缺解釋性。</span><span class="sxs-lookup"><span data-stu-id="e8421-155">Except for Generalized Additive Models (GAMs), tree models can lack explainability when the number of features is large.</span></span>

<span data-ttu-id="e8421-156">決策樹演算法需要更多資源，且不像線性演算法縮放自如。</span><span class="sxs-lookup"><span data-stu-id="e8421-156">Decision tree algorithms take more resources and do not scale as well as linear ones do.</span></span> <span data-ttu-id="e8421-157">它們也很適合貼近記憶體的資料集。</span><span class="sxs-lookup"><span data-stu-id="e8421-157">They do perform well on datasets that can fit into memory.</span></span>

<span data-ttu-id="e8421-158">促進式決策樹是一整團的小型樹狀結構，其中每個樹狀結構都會評分輸入資料，並將分數傳遞到下一個樹狀結構，以產生更好的分數，整體中的每個樹狀結構都可以改善前一個樹狀結構。</span><span class="sxs-lookup"><span data-stu-id="e8421-158">Boosted decision trees are an ensemble of small trees where each tree scores the input data and passes the score onto the next tree to produce a better score, and so on, where each tree in the ensemble improves on the previous.</span></span>

<span data-ttu-id="e8421-159">**決策樹定型器**</span><span class="sxs-lookup"><span data-stu-id="e8421-159">**Decision tree trainers**</span></span>

|<span data-ttu-id="e8421-160">演算法</span><span class="sxs-lookup"><span data-stu-id="e8421-160">Algorithm</span></span>|<span data-ttu-id="e8421-161">屬性</span><span class="sxs-lookup"><span data-stu-id="e8421-161">Properties</span></span>|<span data-ttu-id="e8421-162">定型器</span><span class="sxs-lookup"><span data-stu-id="e8421-162">Trainers</span></span>|
|---------|----------|--------|
|<span data-ttu-id="e8421-163">輕量型梯度提升機器</span><span class="sxs-lookup"><span data-stu-id="e8421-163">Light gradient boosted machine</span></span>|<span data-ttu-id="e8421-164">最快速且最精確的二元分類樹狀定型器。</span><span class="sxs-lookup"><span data-stu-id="e8421-164">Fastest and most accurate of the binary classification tree trainers.</span></span> <span data-ttu-id="e8421-165">微調程度高</span><span class="sxs-lookup"><span data-stu-id="e8421-165">Highly tunable</span></span>|<span data-ttu-id="e8421-166"><xref:Microsoft.ML.Trainers.LightGbm.LightGbmBinaryTrainer> <xref:Microsoft.ML.Trainers.LightGbm.LightGbmMulticlassTrainer> <xref:Microsoft.ML.Trainers.LightGbm.LightGbmRegressionTrainer> <xref:Microsoft.ML.Trainers.LightGbm.LightGbmRankingTrainer></span><span class="sxs-lookup"><span data-stu-id="e8421-166"><xref:Microsoft.ML.Trainers.LightGbm.LightGbmBinaryTrainer> <xref:Microsoft.ML.Trainers.LightGbm.LightGbmMulticlassTrainer> <xref:Microsoft.ML.Trainers.LightGbm.LightGbmRegressionTrainer> <xref:Microsoft.ML.Trainers.LightGbm.LightGbmRankingTrainer></span></span>|
|<span data-ttu-id="e8421-167">快速的樹狀結構</span><span class="sxs-lookup"><span data-stu-id="e8421-167">Fast tree</span></span>|<span data-ttu-id="e8421-168">用於特徵化影像資料。</span><span class="sxs-lookup"><span data-stu-id="e8421-168">Use for featurized image data.</span></span> <span data-ttu-id="e8421-169">復原不對稱的資料。</span><span class="sxs-lookup"><span data-stu-id="e8421-169">Resilient to unbalanced data.</span></span> <span data-ttu-id="e8421-170">微調程度高</span><span class="sxs-lookup"><span data-stu-id="e8421-170">Highly tunable</span></span> | <span data-ttu-id="e8421-171"><xref:Microsoft.ML.Trainers.FastTree.FastTreeBinaryTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastTreeRegressionTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastTreeTweedieTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastTreeRankingTrainer></span><span class="sxs-lookup"><span data-stu-id="e8421-171"><xref:Microsoft.ML.Trainers.FastTree.FastTreeBinaryTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastTreeRegressionTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastTreeTweedieTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastTreeRankingTrainer></span></span>|
|<span data-ttu-id="e8421-172">快速樹系</span><span class="sxs-lookup"><span data-stu-id="e8421-172">Fast forest</span></span>|<span data-ttu-id="e8421-173">適用於有很多雜訊的資料</span><span class="sxs-lookup"><span data-stu-id="e8421-173">Works well with noisy data</span></span>|<span data-ttu-id="e8421-174"><xref:Microsoft.ML.Trainers.FastTree.FastForestBinaryTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastForestRegressionTrainer></span><span class="sxs-lookup"><span data-stu-id="e8421-174"><xref:Microsoft.ML.Trainers.FastTree.FastForestBinaryTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastForestRegressionTrainer></span></span>|
|<span data-ttu-id="e8421-175">一般化累加模型 (GAM)</span><span class="sxs-lookup"><span data-stu-id="e8421-175">Generalized additive model (GAM)</span></span>|<span data-ttu-id="e8421-176">最適合處理適用樹狀演算法，但解釋性優先的問題</span><span class="sxs-lookup"><span data-stu-id="e8421-176">Best for problems that perform well with tree algorithms but where explainability is a priority</span></span>|<span data-ttu-id="e8421-177"><xref:Microsoft.ML.Trainers.FastTree.GamBinaryTrainer> <xref:Microsoft.ML.Trainers.FastTree.GamRegressionTrainer></span><span class="sxs-lookup"><span data-stu-id="e8421-177"><xref:Microsoft.ML.Trainers.FastTree.GamBinaryTrainer> <xref:Microsoft.ML.Trainers.FastTree.GamRegressionTrainer></span></span>|

## <a name="matrix-factorization"></a><span data-ttu-id="e8421-178">矩陣分解</span><span class="sxs-lookup"><span data-stu-id="e8421-178">Matrix factorization</span></span>

|<span data-ttu-id="e8421-179">屬性</span><span class="sxs-lookup"><span data-stu-id="e8421-179">Properties</span></span>|<span data-ttu-id="e8421-180">定型器</span><span class="sxs-lookup"><span data-stu-id="e8421-180">Trainers</span></span>|
|----------|--------|
|<span data-ttu-id="e8421-181">最適合大型資料集的分類疏鬆資料</span><span class="sxs-lookup"><span data-stu-id="e8421-181">Best for sparse categorical data, with large datasets</span></span>|<xref:Microsoft.ML.Trainers.FieldAwareFactorizationMachineTrainer>|

## <a name="meta-algorithms"></a><span data-ttu-id="e8421-182">中繼演算法</span><span class="sxs-lookup"><span data-stu-id="e8421-182">Meta algorithms</span></span>

<span data-ttu-id="e8421-183">這些定型器從二元定型器建立多元定型器。</span><span class="sxs-lookup"><span data-stu-id="e8421-183">These trainers create a multi-class trainer from a binary trainer.</span></span> <span data-ttu-id="e8421-184">搭配使用 <xref:Microsoft.ML.Trainers.AveragedPerceptronTrainer><xref:Microsoft.ML.Trainers.LbfgsLogisticRegressionBinaryTrainer>、<xref:Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer>、<xref:Microsoft.ML.Trainers.LightGbm.LightGbmBinaryTrainer><xref:Microsoft.ML.Trainers.FastTree.FastTreeBinaryTrainer><xref:Microsoft.ML.Trainers.FastTree.FastForestBinaryTrainer>、<xref:Microsoft.ML.Trainers.FastTree.GamBinaryTrainer>。</span><span class="sxs-lookup"><span data-stu-id="e8421-184">Use with <xref:Microsoft.ML.Trainers.AveragedPerceptronTrainer>, <xref:Microsoft.ML.Trainers.LbfgsLogisticRegressionBinaryTrainer>, <xref:Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer>, <xref:Microsoft.ML.Trainers.LightGbm.LightGbmBinaryTrainer>, <xref:Microsoft.ML.Trainers.FastTree.FastTreeBinaryTrainer>, <xref:Microsoft.ML.Trainers.FastTree.FastForestBinaryTrainer>, <xref:Microsoft.ML.Trainers.FastTree.GamBinaryTrainer>.</span></span>

|<span data-ttu-id="e8421-185">演算法</span><span class="sxs-lookup"><span data-stu-id="e8421-185">Algorithm</span></span>|<span data-ttu-id="e8421-186">屬性</span><span class="sxs-lookup"><span data-stu-id="e8421-186">Properties</span></span>|<span data-ttu-id="e8421-187">定型器</span><span class="sxs-lookup"><span data-stu-id="e8421-187">Trainers</span></span>|
|---------|----------|--------|
|<span data-ttu-id="e8421-188">一對多</span><span class="sxs-lookup"><span data-stu-id="e8421-188">One versus all</span></span>|<span data-ttu-id="e8421-189">此多元分類器每類別定型一個二元分類器，從所有其他類別中區分出該類別。</span><span class="sxs-lookup"><span data-stu-id="e8421-189">This multiclass classifier trains one binary classifier for each class, which distinguishes that class from all other classes.</span></span> <span data-ttu-id="e8421-190">規模受限於要分類的類別數目</span><span class="sxs-lookup"><span data-stu-id="e8421-190">Is limited in scale by the number of classes to categorize</span></span>|[<span data-ttu-id="e8421-191">OneVersusAllTrainer<BinaryClassificationTrainer></span><span class="sxs-lookup"><span data-stu-id="e8421-191">OneVersusAllTrainer<BinaryClassificationTrainer></span></span>](xref:Microsoft.ML.Trainers.OneVersusAllTrainer) |
|<span data-ttu-id="e8421-192">成對結合</span><span class="sxs-lookup"><span data-stu-id="e8421-192">Pairwise coupling</span></span>|<span data-ttu-id="e8421-193">此多元分類器針對每對類別定型二元分類演算法。</span><span class="sxs-lookup"><span data-stu-id="e8421-193">This multiclass classifier trains a binary classification algorithm on each pair of classes.</span></span> <span data-ttu-id="e8421-194">規模受限於類別數目，因為必須定型每對類別的組合。</span><span class="sxs-lookup"><span data-stu-id="e8421-194">Is limited in scale by the number of classes, as each combination of two classes must be trained.</span></span>|[<span data-ttu-id="e8421-195">PairwiseCouplingTrainer<BinaryClassificationTrainer></span><span class="sxs-lookup"><span data-stu-id="e8421-195">PairwiseCouplingTrainer<BinaryClassificationTrainer></span></span>](xref:Microsoft.ML.Trainers.PairwiseCouplingTrainer)|

## <a name="k-means"></a><span data-ttu-id="e8421-196">K-Means</span><span class="sxs-lookup"><span data-stu-id="e8421-196">K-Means</span></span>

|<span data-ttu-id="e8421-197">屬性</span><span class="sxs-lookup"><span data-stu-id="e8421-197">Properties</span></span>|<span data-ttu-id="e8421-198">定型器</span><span class="sxs-lookup"><span data-stu-id="e8421-198">Trainers</span></span>|
|----------|--------|
|<span data-ttu-id="e8421-199">用於叢集</span><span class="sxs-lookup"><span data-stu-id="e8421-199">Use for clustering</span></span>|<xref:Microsoft.ML.Trainers.KMeansTrainer>|

## <a name="principal-component-analysis"></a><span data-ttu-id="e8421-200">主體元件分析</span><span class="sxs-lookup"><span data-stu-id="e8421-200">Principal component analysis</span></span>

|<span data-ttu-id="e8421-201">屬性</span><span class="sxs-lookup"><span data-stu-id="e8421-201">Properties</span></span>|<span data-ttu-id="e8421-202">定型器</span><span class="sxs-lookup"><span data-stu-id="e8421-202">Trainers</span></span>|
|----------|--------|
|<span data-ttu-id="e8421-203">用於異常偵測</span><span class="sxs-lookup"><span data-stu-id="e8421-203">Use for anomaly detection</span></span>|<xref:Microsoft.ML.Trainers.RandomizedPcaTrainer>|

## <a name="naive-bayes"></a><span data-ttu-id="e8421-204">貝氏機率分類</span><span class="sxs-lookup"><span data-stu-id="e8421-204">Naive Bayes</span></span>

|<span data-ttu-id="e8421-205">屬性</span><span class="sxs-lookup"><span data-stu-id="e8421-205">Properties</span></span>|<span data-ttu-id="e8421-206">定型器</span><span class="sxs-lookup"><span data-stu-id="e8421-206">Trainers</span></span>|
|----------|--------|
|<span data-ttu-id="e8421-207">當特性獨立存在且定型資料集很小時，請使用此多元分類定型器。</span><span class="sxs-lookup"><span data-stu-id="e8421-207">Use this multi-class classification trainer when the features are independent, and the training dataset is small.</span></span>|<xref:Microsoft.ML.Trainers.NaiveBayesMulticlassTrainer>|

## <a name="prior-trainer"></a><span data-ttu-id="e8421-208">舊的定型器</span><span class="sxs-lookup"><span data-stu-id="e8421-208">Prior Trainer</span></span>

|<span data-ttu-id="e8421-209">屬性</span><span class="sxs-lookup"><span data-stu-id="e8421-209">Properties</span></span>|<span data-ttu-id="e8421-210">定型器</span><span class="sxs-lookup"><span data-stu-id="e8421-210">Trainers</span></span>|
|----------|--------|
|<span data-ttu-id="e8421-211">使用此二元分類定型器建立其他定型器的效能基準。</span><span class="sxs-lookup"><span data-stu-id="e8421-211">Use this binary classification trainer to baseline the performance of other trainers.</span></span> <span data-ttu-id="e8421-212">為有效率，其他定型器的計量應該比舊定型器好。</span><span class="sxs-lookup"><span data-stu-id="e8421-212">To be effective, the metrics of the other trainers should be better than the prior trainer.</span></span> |<xref:Microsoft.ML.Trainers.PriorTrainer>|

